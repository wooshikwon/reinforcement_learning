# Homework 3: Q-Learning ì™„ë£Œ ì‘ì—… ë¦¬ìŠ¤íŠ¸

## ê³¼ì œ ê°œìš”
ì´ ë¬¸ì„œëŠ” GCB6206 Homework 3 (Q-Learning) ê³¼ì œë¥¼ ì™„ë£Œí•˜ê¸° ìœ„í•´ í•´ì•¼ í•  ëª¨ë“  ì‘ì—…ì„ ìˆœì„œëŒ€ë¡œ ì •ë¦¬í•œ ì²´í¬ë¦¬ìŠ¤íŠ¸ì…ë‹ˆë‹¤.

---

## Section 1: ì´ë¡  í€´ì¦ˆ (5ë¶„)

### 1. DQN í€´ì¦ˆ 4ë¬¸ì œ True/False ë‹µë³€ ì‘ì„±
- [ ] **Quiz I**: False (Q-learningì€ off-policyë¡œ ë†’ì€ sample efficiency)
- [ ] **Quiz II**: True (ì—°ì† í–‰ë™ ê³µê°„ì—ì„œëŠ” actor í•„ìš”)
- [ ] **Quiz III**: True (Moving target ë¬¸ì œ í•´ê²°ìœ„í•´ target network ì‚¬ìš©)
- [ ] **Quiz IV**: False (ì‹œê°„ì— ë”°ë¼ explorationì„ ì¤„ì„, ëŠ˜ë¦¬ëŠ” ê²Œ ì•„ë‹˜)

---

## Section 2: ì½”ë“œ êµ¬ì¡° ì´í•´ (30ë¶„)

### 2. ì£¼ìš” íŒŒì¼ë“¤ ì½ê³  ì´í•´í•˜ê¸°
- [ ] `gcb6206/env_configs/dqn_basic_config.py` ì½ê¸°
- [ ] `gcb6206/env_configs/dqn_atari_config.py` ì½ê¸°
- [ ] `gcb6206/infrastructure/replay_buffer.py` ì½ê¸°
- [ ] `gcb6206/infrastructure/atari_wrappers.py` ì½ê¸°

---

## Section 3: DQN êµ¬í˜„ (2-3ì‹œê°„)

### 3.1 DQN Agent êµ¬í˜„ (`gcb6206/agents/dqn_agent.py`)

#### 3. `get_action()` ë©”ì„œë“œ êµ¬í˜„ - Epsilon-greedy í–‰ë™ ì„ íƒ
- [ ] Epsilon-greedy ë¡œì§ êµ¬í˜„
  ```python
  if np.random.random() < epsilon:
      action = np.random.randint(self.num_actions)  # Exploration
  else:
      with torch.no_grad():
          q_values = self.critic(observation)
          action = torch.argmax(q_values, dim=1)  # Exploitation
  ```

#### 4. `update_critic()` ë©”ì„œë“œ êµ¬í˜„ - DQN critic ì—…ë°ì´íŠ¸
- [ ] Target values ê³„ì‚°
  ```python
  with torch.no_grad():
      next_qa_values = self.target_critic(next_obs)
      if self.use_double_q:
          next_action = torch.argmax(self.critic(next_obs), dim=1)
      else:
          next_action = torch.argmax(next_qa_values, dim=1)
      next_q_values = torch.gather(next_qa_values, 1, next_action.unsqueeze(1)).squeeze(1)
      target_values = reward + self.discount * (1 - done) * next_q_values
  ```
- [ ] Q-values ê³„ì‚°
  ```python
  qa_values = self.critic(obs)
  q_values = torch.gather(qa_values, 1, action.unsqueeze(1)).squeeze(1)
  ```
- [ ] Loss ê³„ì‚° ë° backpropagation
  ```python
  loss = self.critic_loss(q_values, target_values)
  ```

#### 5. `update()` ë©”ì„œë“œ êµ¬í˜„ - Main update logic
- [ ] Critic ì—…ë°ì´íŠ¸ í˜¸ì¶œ
- [ ] Target network ì£¼ê¸°ì  ì—…ë°ì´íŠ¸
  ```python
  critic_stats = self.update_critic(obs, action, reward, next_obs, done)
  if step % self.target_update_period == 0:
      self.update_target_critic()
  return critic_stats
  ```

### 3.2 Training Loop êµ¬í˜„ (`gcb6206/scripts/run_hw3.py`)

#### 6. Training loop TODOs êµ¬í˜„
- [ ] Action ê³„ì‚°
  ```python
  action = agent.get_action(observation, epsilon=epsilon)
  ```
- [ ] Environment step
  ```python
  next_observation, reward, terminated, truncated, info = env.step(action)
  ```
- [ ] Replay buffer insertion (regular buffer)
  ```python
  replay_buffer.insert(
      observation=observation,
      action=action,
      reward=reward,
      next_observation=next_observation,
      done=terminated,
  )
  ```
- [ ] Batch sampling
  ```python
  batch = replay_buffer.sample(config["batch_size"])
  ```
- [ ] Agent update
  ```python
  update_info = agent.update(
      obs=batch["observations"],
      action=batch["actions"],
      reward=batch["rewards"],
      next_obs=batch["next_observations"],
      done=batch["dones"],
      step=step,
  )
  ```

### 3.3 Trajectory Sampling êµ¬í˜„ (`gcb6206/infrastructure/utils.py`)

#### 7. `sample_trajectory()` TODOs êµ¬í˜„
- [ ] Action selection
  ```python
  ac = agent.get_action(ob)
  ```
- [ ] Environment step
  ```python
  next_ob, rew, terminated, truncated, info = env.step(ac)
  ```
- [ ] Rollout done flag (terminated or truncated)
  ```python
  rollout_done = terminated or truncated
  ```

---

## Section 4: DQN ì‹¤í—˜ (1-2ì‹œê°„)

### 4.1 CartPole ê¸°ë³¸ ì‹¤í—˜

#### 8. CartPole-v1 ì‹¤í—˜ ì‹¤í–‰ (~15ë¶„)
- [ ] ì‹¤í—˜ ì‹¤í–‰
  ```bash
  python gcb6206/scripts/run_hw3.py -cfg experiments/dqn/cartpole.yaml --seed 1
  ```
- [ ] ëª©í‘œ: eval_return ~500

#### 9. Learning curve plot ìƒì„±
- [ ] Xì¶•: environment steps
- [ ] Yì¶•: eval_return
- [ ] Caption ì‘ì„±
- [ ] Plot ì €ì¥

### 4.2 Learning Rate ë¹„êµ ì‹¤í—˜

#### 10. Config íŒŒì¼ ìƒì„±
- [ ] `experiments/dqn/cartpole_lr_5e-2.yaml` ìƒì„±
- [ ] learning_rate: 0.05ë¡œ ë³€ê²½

#### 11. ë†’ì€ LR ì‹¤í—˜ ì‹¤í–‰ (~15ë¶„)
- [ ] ì‹¤í—˜ ì‹¤í–‰
  ```bash
  python gcb6206/scripts/run_hw3.py -cfg experiments/dqn/cartpole_lr_5e-2.yaml --seed 1
  ```

#### 12. 3ê°œ ë¹„êµ plot ìƒì„±
- [ ] (a) Predicted Q-values ë¹„êµ
- [ ] (b) Critic error ë¹„êµ
- [ ] (c) Eval returns ë¹„êµ
- [ ] ê° plotì— caption ì¶”ê°€

#### 13. ê²°ê³¼ ë¶„ì„ ë° ì„¤ëª… ì‘ì„±
- [ ] ë†’ì€ LRì˜ ì˜í–¥ ì„¤ëª…
- [ ] ê°•ì˜ ë‚´ìš©ê³¼ ì—°ê²°
- [ ] Trade-off ë¶„ì„

---

## Section 5: Double DQN êµ¬í˜„ ë° ì‹¤í—˜ (12-24ì‹œê°„)

### 5.1 Double DQN êµ¬í˜„

#### 14. `update_critic()` ë‚´ Double Q-Learning ë¡œì§ êµ¬í˜„
- [ ] Online networkë¡œ action selection
- [ ] Target networkë¡œ value estimation
- [ ] êµ¬í˜„ í™•ì¸ (ì´ë¯¸ Section 3.1ì—ì„œ ì™„ë£Œë¨)

### 5.2 BankHeist ì‹¤í—˜

#### 15. Vanilla DQN ì‹¤í—˜ (3 seeds) (~6ì‹œê°„ GPU / 12ì‹œê°„ CPU)
- [ ] Seed 1 ì‹¤í—˜
  ```bash
  python gcb6206/scripts/run_hw3.py -cfg experiments/dqn/bankheist.yaml --seed 1
  ```
- [ ] Seed 2 ì‹¤í—˜
  ```bash
  python gcb6206/scripts/run_hw3.py -cfg experiments/dqn/bankheist.yaml --seed 2
  ```
- [ ] Seed 3 ì‹¤í—˜
  ```bash
  python gcb6206/scripts/run_hw3.py -cfg experiments/dqn/bankheist.yaml --seed 3
  ```
- [ ] ëª©í‘œ: eval_return ~150

#### 16. Double DQN ì‹¤í—˜ (3 seeds) (~6ì‹œê°„ GPU / 12ì‹œê°„ CPU)
- [ ] Seed 1 ì‹¤í—˜
  ```bash
  python gcb6206/scripts/run_hw3.py -cfg experiments/dqn/bankheist_ddqn.yaml --seed 1
  ```
- [ ] Seed 2 ì‹¤í—˜
  ```bash
  python gcb6206/scripts/run_hw3.py -cfg experiments/dqn/bankheist_ddqn.yaml --seed 2
  ```
- [ ] Seed 3 ì‹¤í—˜
  ```bash
  python gcb6206/scripts/run_hw3.py -cfg experiments/dqn/bankheist_ddqn.yaml --seed 3
  ```
- [ ] ëª©í‘œ: eval_return ~300

#### 17. ë¹„êµ plot ìƒì„±
- [ ] DQN 3 curves (blue)
- [ ] Double DQN 3 curves (red)
- [ ] ê°™ì€ axesì— í‘œì‹œ
- [ ] Legend ì¶”ê°€
- [ ] Caption ì‘ì„±

#### 18. ê²°ê³¼ ë¶„ì„ ë° ì„¤ëª… ì‘ì„±
- [ ] Double DQNì˜ ì„±ëŠ¥ í–¥ìƒ ì„¤ëª…
- [ ] Overestimation bias ê°ì†Œ ë©”ì»¤ë‹ˆì¦˜ ì„¤ëª…
- [ ] 3 seeds ê²°ê³¼ì˜ ì¼ê´€ì„± ë…¼ì˜

---

## Section 6: Hyperparameter ì‹¤í—˜ (1-2ì‹œê°„)

#### 19. Hyperparameter ì„ íƒ
- [ ] ì„ íƒí•œ hyperparameter ê²°ì • (ì˜ˆ: exploration schedule, learning rate, network architecture ë“±)
- [ ] ì„ íƒ ì´ìœ  ì‘ì„±

#### 20. 4ê°œ config íŒŒì¼ ìƒì„±
- [ ] `experiments/dqn/hyperparameters/` ë””ë ‰í† ë¦¬ ìƒì„±
- [ ] Config 1 (default) ìƒì„±
- [ ] Config 2 ìƒì„±
- [ ] Config 3 ìƒì„±
- [ ] Config 4 ìƒì„±

#### 21. 4ê°€ì§€ ì‹¤í—˜ ì‹¤í–‰ (~1ì‹œê°„)
- [ ] Config 1 ì‹¤í—˜
- [ ] Config 2 ì‹¤í—˜
- [ ] Config 3 ì‹¤í—˜
- [ ] Config 4 ì‹¤í—˜

#### 22. ë¹„êµ plot ìƒì„±
- [ ] 4 curves í‘œì‹œ
- [ ] ë‹¤ë¥¸ ìƒ‰ìƒ ì‚¬ìš©
- [ ] Legend ì¶”ê°€
- [ ] Caption ì‘ì„±

#### 23. ë¶„ì„ ë° ì„¤ëª… ì‘ì„±
- [ ] Hyperparameter ì„ íƒ ì´ìœ 
- [ ] ê° ì„¤ì •ì˜ ì˜ë¯¸ ì„¤ëª…
- [ ] ê²°ê³¼ ê´€ì°° ë° ë¶„ì„
- [ ] ì´ë¡ ì  ì„¤ëª…
- [ ] ê²°ë¡  ë° ìµœì  ì„¤ì •

---

## Section 7: ìµœì¢… ì œì¶œ ì¤€ë¹„ (1ì‹œê°„)

#### 24. ëª¨ë“  plot ê²€í†  ë° caption ì‘ì„±
- [ ] Section 4.2: CartPole DQN plot
- [ ] Section 4.2: Learning rate ë¹„êµ plots (3ê°œ)
- [ ] Section 5.2: BankHeist DQN vs Double DQN plot
- [ ] Section 6: Hyperparameter ë¹„êµ plot
- [ ] ëª¨ë“  caption ì™„ì„±ë„ í™•ì¸

#### 25. ì„¤ëª…/ë¶„ì„ í…ìŠ¤íŠ¸ ì‘ì„±
- [ ] Quiz ë‹µë³€ ì™„ë£Œ
- [ ] CartPole LR ì‹¤í—˜ ì„¤ëª…
- [ ] BankHeist ë¹„êµ ì„¤ëª…
- [ ] Hyperparameter ë¶„ì„

#### 26. PDF ë³´ê³ ì„œ ì‘ì„±
- [ ] ì´ë¦„/í•™ë²ˆ ì…ë ¥
- [ ] Section 2: Quiz ë‹µë³€
- [ ] Section 4.2: CartPole plots + ì„¤ëª…
- [ ] Section 4.2: LR ë¹„êµ plots + ì„¤ëª…
- [ ] Section 5.2: BankHeist plot + ì„¤ëª…
- [ ] Section 6: Hyperparameter plot + ì„¤ëª…
- [ ] ì „ì²´ formatting í™•ì¸

#### 27. ì œì¶œ íŒŒì¼ êµ¬ì¡°í™”
- [ ] íŒŒì¼ êµ¬ì¡° í™•ì¸
  ```
  hw3_[YourStudentID].zip
  â”œâ”€â”€ hw3_[YourStudentID].pdf
  â”œâ”€â”€ gcb6206/
  â”‚   â”œâ”€â”€ agents/
  â”‚   â”‚   â””â”€â”€ dqn_agent.py
  â”‚   â”œâ”€â”€ scripts/
  â”‚   â”‚   â””â”€â”€ run_hw3.py
  â”‚   â”œâ”€â”€ infrastructure/
  â”‚   â”‚   â””â”€â”€ utils.py
  â”‚   â””â”€â”€ ...codes
  â””â”€â”€ data/
      â”œâ”€â”€ hw3_dqn_cartpole/
      â”œâ”€â”€ hw3_dqn_bankheist/
      â””â”€â”€ ...
          â””â”€â”€ events.out.tfevents....
  ```

#### 28. íŒŒì¼ í¬ê¸° í™•ì¸
- [ ] ì´ í¬ê¸° < 50MB
- [ ] ë¹„ë””ì˜¤ íŒŒì¼ ì œì™¸ í™•ì¸
- [ ] ë¶ˆí•„ìš”í•œ íŒŒì¼ ì‚­ì œ

#### 29. ìµœì¢… ì œì¶œ
- [ ] ZIP íŒŒì¼ ìƒì„±
- [ ] íŒŒì¼ëª… í™•ì¸: `hw3_[YourStudentID].zip`
- [ ] ì œì¶œ

---

## ì¶”ì • ì´ ì†Œìš” ì‹œê°„

| ì‘ì—… ë‹¨ê³„ | ì˜ˆìƒ ì‹œê°„ |
|---------|---------|
| **êµ¬í˜„** | 3-4ì‹œê°„ |
| **CartPole ì‹¤í—˜** | 1ì‹œê°„ |
| **BankHeist ì‹¤í—˜** | 12-24ì‹œê°„ (GPU/CPU) |
| **Hyperparameter ì‹¤í—˜** | 1-2ì‹œê°„ |
| **ë³´ê³ ì„œ ì‘ì„±** | 1-2ì‹œê°„ |
| **ì´ê³„** | **~18-33ì‹œê°„** |

---

## ì¤‘ìš” ì°¸ê³  ì‚¬í•­

### âš ï¸ ìš°ì„ ìˆœìœ„ ë†’ì€ ì‘ì—…
1. **Section 5.2 BankHeist ì‹¤í—˜ì„ ìµœëŒ€í•œ ë¹¨ë¦¬ ì‹œì‘**
   - ì‹¤í—˜ ì‹œê°„ì´ ê°€ì¥ ì˜¤ë˜ ê±¸ë¦¼ (12-24ì‹œê°„)
   - GPU ì‚¬ìš© ê¶Œì¥ (VESSL AI ë˜ëŠ” Colab)
   - 3 seeds Ã— 2 methods = ì´ 6ê°œ ì‹¤í—˜

### ğŸ’¡ íŒ
- **ë³‘ë ¬ ì‹¤í–‰**: ì—¬ëŸ¬ seedë¥¼ ë™ì‹œì— ë‹¤ë¥¸ GPU/ë¨¸ì‹ ì—ì„œ ì‹¤í–‰
- **ì²´í¬í¬ì¸íŠ¸**: ì‹¤í—˜ ì¤‘ê°„ì¤‘ê°„ ê²°ê³¼ í™•ì¸
- **ë””ë²„ê¹…**: CartPoleì—ì„œ ë¨¼ì € êµ¬í˜„ ê²€ì¦ í›„ Atarië¡œ ì§„í–‰
- **TensorBoard**: ì‹¤ì‹œê°„ìœ¼ë¡œ í•™ìŠµ ê³¡ì„  ëª¨ë‹ˆí„°ë§
  ```bash
  tensorboard --logdir data/
  ```

### ğŸ“ ì°¸ê³  ë¬¸ì„œ
- `solution_guide_section1.md`: Quiz ë‹µë³€ ë° ì´ë¡  ì„¤ëª…
- `solution_guide_section2.md`: ì½”ë“œ êµ¬ì¡° ë° replay buffer
- `solution_guide_section3.md`: DQN agent êµ¬í˜„ ìƒì„¸
- `solution_guide_section4.md`: Training loop êµ¬í˜„ ìƒì„¸
- `solution_guide_section5.md`: Double DQN ë° ì‹¤í—˜ ê°€ì´ë“œ

---

## ì§„í–‰ ìƒí™© ì¶”ì 

- **ì‹œì‘ì¼**: ___________
- **ì˜ˆìƒ ì™„ë£Œì¼**: ___________
- **ì‹¤ì œ ì™„ë£Œì¼**: ___________

### ë§ˆì¼ìŠ¤í†¤
- [ ] êµ¬í˜„ ì™„ë£Œ (Section 3)
- [ ] CartPole ì‹¤í—˜ ì™„ë£Œ (Section 4)
- [ ] BankHeist ì‹¤í—˜ ì‹œì‘ (Section 5)
- [ ] BankHeist ì‹¤í—˜ ì™„ë£Œ (Section 5)
- [ ] Hyperparameter ì‹¤í—˜ ì™„ë£Œ (Section 6)
- [ ] ë³´ê³ ì„œ ì‘ì„± ì™„ë£Œ (Section 7)
- [ ] ìµœì¢… ì œì¶œ ì™„ë£Œ

---

**Good Luck!** ğŸš€
